{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_v3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNL1hw6fJcN3JFinqM8VdTw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066407e67a334e2c9eb30fd70e90865d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eceb053a76a94c69a22db305c176ecd7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b748bea21b3a401dac9f7f5199eb7695",
              "IPY_MODEL_ba3dc6ae1b964a90a8da3ed7bd59959e"
            ]
          }
        },
        "eceb053a76a94c69a22db305c176ecd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b748bea21b3a401dac9f7f5199eb7695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2621f05bd4a4d6584c831489b2d0e6e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79e590d0c3974f6aa994b546a78030e9"
          }
        },
        "ba3dc6ae1b964a90a8da3ed7bd59959e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f98dbfc3d6241d69dbfb403cd5ce8bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 91.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03706c28db19418e8a23fb5cb2b016a9"
          }
        },
        "d2621f05bd4a4d6584c831489b2d0e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79e590d0c3974f6aa994b546a78030e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f98dbfc3d6241d69dbfb403cd5ce8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03706c28db19418e8a23fb5cb2b016a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41710ff70921448f91a5a1ffe4024f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_515fa05dfd0545af9109fadfd053cfc6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f15093d2e6db42cc8c6e9c9f9913c40e",
              "IPY_MODEL_6aee97fb09534acb8ae873af3f250bae"
            ]
          }
        },
        "515fa05dfd0545af9109fadfd053cfc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f15093d2e6db42cc8c6e9c9f9913c40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10feb342f9954c89a169536ba247fa2d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_746305292c2d4ad58dddb5c7bdc07787"
          }
        },
        "6aee97fb09534acb8ae873af3f250bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_640c5160d11e48cb8f5133a19bae0a70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 78.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4d2cdf14ff348aba32efb8bad734d30"
          }
        },
        "10feb342f9954c89a169536ba247fa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "746305292c2d4ad58dddb5c7bdc07787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "640c5160d11e48cb8f5133a19bae0a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4d2cdf14ff348aba32efb8bad734d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBcORxSlRQUk",
        "outputId": "f24c9443-d856-41fc-de82-f597b2f80363"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D58zCWalRYEA"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append('/content/drive/MyDrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8vg8H2yRc-N"
      },
      "source": [
        "import torch\r\n",
        "import os\r\n",
        "import time\r\n",
        "import shutil\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torchvision\r\n",
        "import torch.optim as optim\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchvision import transforms, utils, models\r\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGpRljcORfXK",
        "outputId": "298cb2b4-34db-4783-9ece-9cb2b6ed6806"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/Object-CXR/DATA_DIR'\r\n",
        "train_dir = os.path.join(data_dir, 'train')\r\n",
        "dev_dir = os.path.join(data_dir, 'dev')\r\n",
        "print(train_dir)\r\n",
        "print(dev_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Object-CXR/DATA_DIR/train\n",
            "/content/drive/MyDrive/Object-CXR/DATA_DIR/dev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I924EzgpRp-O"
      },
      "source": [
        "class ObjectDataset(Dataset):\r\n",
        "    \"\"\"\r\n",
        "    Creates a Dataset object of the images and their corresponding labels.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\r\n",
        "        \"\"\"\r\n",
        "        :param csv_file (string): Path to the csv file with annotations\r\n",
        "        :param root_dir (string): Directory with all the images\r\n",
        "        :param transform (callable, optional): Optional transform to be applied on a sample\r\n",
        "        \"\"\"\r\n",
        "        self.frame = pd.read_csv(csv_file, na_filter=False)\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.transform = transform\r\n",
        "        # Renaming the 'annotation' column and calling it 'label'\r\n",
        "        self.frame = self.frame.rename(columns={\"annotation\": \"label\"})\r\n",
        "        # Now we change the content of the label column\r\n",
        "        # If content is empty i.e. \"\", then label it 0\r\n",
        "        # Otherwise, label it 1\r\n",
        "        num_index = range(len(self.frame))\r\n",
        "        for idx in num_index:\r\n",
        "            label = self.frame.loc[idx, 'label']\r\n",
        "            if label == \"\":\r\n",
        "                self.frame.loc[idx, 'label'] = 0\r\n",
        "            else:\r\n",
        "                self.frame.loc[idx, 'label'] = 1\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.frame)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if torch.is_tensor(idx):\r\n",
        "            idx = idx.tolist()\r\n",
        "\r\n",
        "        img_name = os.path.join(self.root_dir,\r\n",
        "                                self.frame.iloc[idx, 0])\r\n",
        "        image = Image.open(img_name).convert(\"RGB\")  # convert image to RGB\r\n",
        "\r\n",
        "        replaced_label = self.frame.loc[idx, \"label\"]\r\n",
        "\r\n",
        "        # Applying transforms\r\n",
        "        if self.transform:\r\n",
        "            for tsfrm in self.transform:\r\n",
        "                image = tsfrm(image)\r\n",
        "\r\n",
        "        sample = {\"image\": image, \"label\": replaced_label}\r\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPkfvZihR6j-"
      },
      "source": [
        "# Defining our transforms\r\n",
        "img_transforms_tr = [transforms.Compose([transforms.RandomAffine(degrees=(-30, 30),\r\n",
        "                                                                 translate=(0.1, 0.1),\r\n",
        "                                                                 shear=(-15, 15))]),\r\n",
        "                     transforms.Compose([transforms.RandomHorizontalFlip(p=0.5)]),\r\n",
        "                     transforms.Compose([transforms.RandomVerticalFlip(p=0.5)]),\r\n",
        "                     transforms.Compose([transforms.Resize([800, 800])]),\r\n",
        "                     transforms.Compose([transforms.ToTensor()]),\r\n",
        "                     transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406],\r\n",
        "                                                              [0.229, 0.224, 0.225])])\r\n",
        "                     ]\r\n",
        "\r\n",
        "img_transforms_dev = [transforms.Compose([transforms.Resize([800, 800])]),\r\n",
        "                      transforms.Compose([transforms.ToTensor()]),\r\n",
        "                      transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406],\r\n",
        "                                                               [0.229, 0.224, 0.225])])\r\n",
        "                      ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR_tD2MUSDZo"
      },
      "source": [
        "# train dataset with transforms\r\n",
        "train_dataset = ObjectDataset(csv_file=data_dir + '/train.csv',\r\n",
        "                                             root_dir=train_dir,\r\n",
        "                                             transform=img_transforms_tr)\r\n",
        "# train_dataset.set_format(type='torch', columns=['label'])\r\n",
        "dev_dataset = ObjectDataset(csv_file=data_dir + '/dev.csv',\r\n",
        "                                           root_dir=dev_dir,\r\n",
        "                                           transform=img_transforms_dev)\r\n",
        "# dev_dataset.set_format(type='torch', columns=['label'])\r\n",
        "\r\n",
        "# Using DataLoader to load our data\r\n",
        "train_dataLoader = DataLoader(train_dataset, batch_size=8, shuffle=True,\r\n",
        "                              num_workers=4)\r\n",
        "val_dataLoader = DataLoader(dev_dataset, batch_size=8, shuffle=False,\r\n",
        "                            num_workers=4)\r\n",
        "dataLoaders_dict = {\"train\": train_dataLoader, \"val\": val_dataLoader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76_WBXlm0N4"
      },
      "source": [
        "# --- Helper functions for initialising our inception v3 model ---\r\n",
        "def set_parameter_requires_grad(model, feature_extracting):\r\n",
        "    \"\"\"\r\n",
        "    This function sets the .requires_grad attribute of the parameters\r\n",
        "    in the model to False when we are feature extracting. By default, when\r\n",
        "    we load a pretrained model all of the parameters have .requires_grad=True,\r\n",
        "    which is fine if we are training from scratch or fine-tuning. However,\r\n",
        "    if we are feature extracting and only want to compute gradients for the\r\n",
        "    newly initialised layer then we want all of the other parameters to not\r\n",
        "    require gradients.\r\n",
        "\r\n",
        "    :param model: The model containing the .requires_grad attributes\r\n",
        "    :param feature_extracting: Determines whether the .requires_grad\r\n",
        "                               attribute of the parameters are set.\r\n",
        "                               If True, param.requires_grad=False,\r\n",
        "                               otherwise param.requires_grad=True\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    if feature_extracting:\r\n",
        "        for param in model.parameters():\r\n",
        "            param.requires_grad = False\r\n",
        "\r\n",
        "\r\n",
        "def initialise_inception_v3(num_classes, feature_extract, input_size, use_pretrained=True):\r\n",
        "    \"\"\"\r\n",
        "    This function initialises an Inception v3 model.\r\n",
        "\r\n",
        "    :param num_classes: The number of classes your Inception v3 model outputs.\r\n",
        "    :param feature_extract: Determines whether the .requires_grad attribute of the\r\n",
        "                            parameters are set. If True, param.requires_grad=False,\r\n",
        "                            otherwise param.requires_grad=True.\r\n",
        "    :param input_size: The size of your image as a single value. For example,\r\n",
        "                       if image size is (800, 800), input_size=800.\r\n",
        "    :param use_pretrained: If True, returns a model pre-trained on ImageNet.\r\n",
        "\r\n",
        "    :return: the inception v3 model, its input size\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    model_ft = models.inception_v3(pretrained=use_pretrained)\r\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\r\n",
        "    # Handle the auxiliary net\r\n",
        "    num_ftrs = model_ft.AuxLogits.fc.in_features\r\n",
        "    model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\r\n",
        "    # Handle the primary net\r\n",
        "    num_ftrs = model_ft.fc.in_features\r\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\r\n",
        "    input_size = input_size\r\n",
        "\r\n",
        "    return model_ft, input_size\r\n",
        "\r\n",
        "\r\n",
        "# --- Helper functions to save checkpoints while training ---\r\n",
        "def save_checkpoint(state, is_best, checkpoint_dir, best_model_dir):\r\n",
        "    f_path = checkpoint_dir + '/checkpoint.pt'\r\n",
        "    torch.save(state, f_path)\r\n",
        "    if is_best:\r\n",
        "      best_fpath = best_model_dir + '/best_model.pt'\r\n",
        "      shutil.copyfile(f_path, best_fpath)\r\n",
        "\r\n",
        "\r\n",
        "def load_checkpoint(checkpoint_fpath, model, optimizer):\r\n",
        "    checkpoint = torch.load(checkpoint_fpath, map_location=\"cuda:0\")\r\n",
        "    model.load_state_dict(checkpoint['state_dict'])\r\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "    return model, optimizer, checkpoint['epoch']\r\n",
        "\r\n",
        "\r\n",
        "# --- Helper functions to train a model ---\r\n",
        "def train_model(model, data_loader, criterion, optimizer, log_path, model_name, num_epochs=10):\r\n",
        "    \"\"\"\r\n",
        "    This function trains a model.\r\n",
        "\r\n",
        "    :param model: The model to be trained.\r\n",
        "    :param data_loader: A python iterator that will return elements from your dataset\r\n",
        "                        batch by batch.\r\n",
        "    :param criterion: The loss function.\r\n",
        "    :param optimizer: The optimizer used to change the attributes of the model.\r\n",
        "    :param log_path: The path to which the performance of your model is logged.\r\n",
        "    :param model_name: The name of the model.\r\n",
        "    :param num_epochs: The number of epochs.\r\n",
        "\r\n",
        "    :return: None\r\n",
        "    \"\"\"\r\n",
        "    use_cuda = torch.cuda.is_available()\r\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "    with open(log_path, 'a') as f:\r\n",
        "        best_auc = 0.0\r\n",
        "        best_epoch = 0\r\n",
        "\r\n",
        "        for epoch in range(num_epochs):\r\n",
        "            print(f\"Epoch {epoch}/{num_epochs - 1}\")\r\n",
        "            print(\"-\" * 10)\r\n",
        "\r\n",
        "            train_loss = 0.0\r\n",
        "            val_loss = 0.0\r\n",
        "\r\n",
        "            train_total = 0\r\n",
        "            val_total = 0\r\n",
        "\r\n",
        "            train_correct = 0\r\n",
        "            val_correct = 0\r\n",
        "\r\n",
        "            preds_prob = torch.empty(0).to(device)\r\n",
        "            gt = torch.empty(0).to(device)\r\n",
        "\r\n",
        "            # Using GPU for model\r\n",
        "            model = model.to(device)\r\n",
        "\r\n",
        "            # Each epoch has a training and validation phase\r\n",
        "            for phase in [\"train\", \"val\"]:\r\n",
        "                if phase == \"train\":\r\n",
        "                    model.train()  # Set model to training mode\r\n",
        "                else:\r\n",
        "                    model.eval()  # Set model to evaluate mode\r\n",
        "\r\n",
        "                # Iterate over data\r\n",
        "                for data in data_loader[phase]:\r\n",
        "                    inputs, labels = data.get('image'), data.get('label')\r\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                    # zero the parameter gradients\r\n",
        "                    optimizer.zero_grad()\r\n",
        "\r\n",
        "                    # forward track history if only in train\r\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\r\n",
        "                        if phase == \"train\":\r\n",
        "                            outputs, aux_outputs = model(inputs)\r\n",
        "                            outputs_prob = torch.nn.Softmax(dim=1)(outputs)\r\n",
        "                            aux_outputs_prob = torch.nn.Softmax(dim=1)(aux_outputs)\r\n",
        "                            loss1 = criterion(outputs_prob, labels)\r\n",
        "                            loss2 = criterion(aux_outputs_prob, labels)\r\n",
        "                            loss = loss1 + 0.4 * loss2\r\n",
        "                        else:\r\n",
        "                            outputs = model(inputs)\r\n",
        "                            outputs_prob = torch.nn.Softmax(dim=1)(outputs)\r\n",
        "                            loss = criterion(outputs_prob, labels)\r\n",
        "\r\n",
        "                        scores, predictions = torch.max(outputs_prob, 1)\r\n",
        "\r\n",
        "                        preds_prob = torch.cat((preds_prob, outputs_prob[:, 1]))\r\n",
        "                        gt_batch = labels.data.float()\r\n",
        "                        gt = torch.cat((gt, labels.data.float()))\r\n",
        "\r\n",
        "                        # backward + optimize only if in training phase\r\n",
        "                        if phase == \"train\":\r\n",
        "                            loss.backward()\r\n",
        "                            optimizer.step()\r\n",
        "                            # calculate loss and accuracy\r\n",
        "                            train_loss += loss.item() * inputs.size(0)\r\n",
        "                            train_total += labels.size(0)\r\n",
        "                            train_correct += int(torch.sum(predictions == labels))\r\n",
        "\r\n",
        "                        if phase == \"val\":\r\n",
        "                            val_loss += loss.item() * inputs.size(0)\r\n",
        "                            scores, predictions = torch.max(outputs.data, 1)\r\n",
        "                            val_total += labels.size(0)\r\n",
        "                            val_correct += int(torch.sum(predictions == labels))\r\n",
        "\r\n",
        "                # save the model to a checkpoint \r\n",
        "                if phase == \"val\":\r\n",
        "                    checkpoint = {\r\n",
        "                    'epoch': epoch,\r\n",
        "                    'state_dict': model.state_dict(),\r\n",
        "                    'optimizer': optimizer.state_dict()\r\n",
        "                    }\r\n",
        "                    checkpoint_dir = '/content/drive/MyDrive/Object-CXR/Inception_v3/Checkpoint'\r\n",
        "                    best_model_dir = '/content/drive/MyDrive/Object-CXR/MODEL_DIR'\r\n",
        "                    fpr, tpr, _ = roc_curve(gt.tolist(), preds_prob.tolist())\r\n",
        "                    epoch_auc = round(auc(fpr, tpr), 3)\r\n",
        "                    is_best = True if (epoch_auc > best_auc) else False\r\n",
        "                    if epoch_auc > best_auc:\r\n",
        "                        best_auc = epoch_auc\r\n",
        "                        best_epoch = epoch\r\n",
        "                    save_checkpoint(checkpoint, is_best, checkpoint_dir, best_model_dir)\r\n",
        "\r\n",
        "            train_loss = round(train_loss/train_total, 3)\r\n",
        "            val_loss = round(val_loss/val_total, 3)\r\n",
        "            train_acc = round((float(train_correct) / train_total) * 100, 2)\r\n",
        "            val_acc = round((float(val_correct) / val_total) * 100, 2)\r\n",
        "\r\n",
        "            print(f\"Epoch: {epoch}, Train loss: {train_loss}, Train accuracy: {train_acc}\")\r\n",
        "            print(f\"\\t\\tVal loss: {val_loss}, Val accuracy: {val_acc}, AUC: {epoch_auc}\")\r\n",
        "\r\n",
        "            # Writing into our log file\r\n",
        "            f.write(f\"{model_name}, \"\r\n",
        "                    f\"{round(time.time(), 2)}, \"\r\n",
        "                    f\"TL: {train_loss}, \"\r\n",
        "                    f\"TA: {train_acc}, \"\r\n",
        "                    f\"VL: {val_loss}, \"\r\n",
        "                    f\"VA: {val_acc}, \"\r\n",
        "                    f\"AUC: {epoch_auc}\\n\")\r\n",
        "\r\n",
        "    print(f\"Training finished. Best AUC: {best_auc} on epoch {best_epoch}\")\r\n",
        "\r\n",
        "\r\n",
        "def resume_training(model, data_loader, criterion, optimizer,\r\n",
        "                    log_path, model_name, start_epoch, best_auc_from_prev,\r\n",
        "                    best_epoch_from_prev, num_epochs=10):\r\n",
        "    \"\"\"\r\n",
        "    This function resumes the training process from a model.\r\n",
        "\r\n",
        "    :param model: The model to be trained.\r\n",
        "    :param data_loader: A python iterator that will return elements from your dataset\r\n",
        "                        batch by batch.\r\n",
        "    :param criterion: The loss function.\r\n",
        "    :param optimizer: The optimizer used to change the attributes of the model.\r\n",
        "    :param log_path: The path to which the performance of your model is logged.\r\n",
        "    :param model_name: The name of the model.\r\n",
        "    :param start_epoch: The starting epoch with which the model is trained in\r\n",
        "                        this training loop.\r\n",
        "    :param best_auc_from_prev: The best auc obtained from the previous training\r\n",
        "                               loop.\r\n",
        "    :param best_epoch_from_prev: The epoch from which the best auc was obtained\r\n",
        "                                 in the previous training loop.\r\n",
        "    :param num_epochs: The number of epochs to train for in this training loop.\r\n",
        "\r\n",
        "    :return: None\r\n",
        "    \"\"\"\r\n",
        "    use_cuda = torch.cuda.is_available()\r\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "    with open(log_path, 'a') as f:\r\n",
        "        best_auc = best_auc_from_prev\r\n",
        "        best_epoch = best_epoch_from_prev\r\n",
        "\r\n",
        "        for epoch in range(start_epoch, start_epoch + num_epochs):\r\n",
        "            print(f\"Epoch {epoch}/{start_epoch + num_epochs - 1}\")\r\n",
        "            print(\"-\" * 10)\r\n",
        "\r\n",
        "            train_loss = 0.0\r\n",
        "            val_loss = 0.0\r\n",
        "\r\n",
        "            train_total = 0\r\n",
        "            val_total = 0\r\n",
        "\r\n",
        "            train_correct = 0\r\n",
        "            val_correct = 0\r\n",
        "\r\n",
        "            preds_prob = torch.empty(0).to(device)\r\n",
        "            gt = torch.empty(0).to(device)\r\n",
        "\r\n",
        "            # Using GPU for model\r\n",
        "            model = model.to(device)\r\n",
        "            \r\n",
        "\r\n",
        "            # Each epoch has a training and validation phase\r\n",
        "            for phase in [\"train\", \"val\"]:\r\n",
        "                if phase == \"train\":\r\n",
        "                    model.train()  # Set model to training mode\r\n",
        "                else:\r\n",
        "                    model.eval()  # Set model to evaluate mode\r\n",
        "\r\n",
        "                # Iterate over data\r\n",
        "                for data in data_loader[phase]:\r\n",
        "                    inputs, labels = data.get('image'), data.get('label')\r\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "\r\n",
        "                    # zero the parameter gradients\r\n",
        "                    optimizer.zero_grad()\r\n",
        "\r\n",
        "                    # forward track history if only in train\r\n",
        "                    with torch.set_grad_enabled(phase == \"train\"):\r\n",
        "                        if phase == \"train\":\r\n",
        "                            outputs, aux_outputs = model(inputs)\r\n",
        "                            outputs_prob = torch.nn.Softmax(dim=1)(outputs)\r\n",
        "                            aux_outputs_prob = torch.nn.Softmax(dim=1)(aux_outputs)\r\n",
        "                            loss1 = criterion(outputs_prob, labels)\r\n",
        "                            loss2 = criterion(aux_outputs_prob, labels)\r\n",
        "                            loss = loss1 + 0.4 * loss2\r\n",
        "                        else:\r\n",
        "                            outputs = model(inputs)\r\n",
        "                            outputs_prob = torch.nn.Softmax(dim=1)(outputs)\r\n",
        "                            loss = criterion(outputs_prob, labels)\r\n",
        "\r\n",
        "                        scores, predictions = torch.max(outputs_prob, 1)\r\n",
        "\r\n",
        "                        preds_prob = torch.cat((preds_prob, outputs_prob[:, 1]))\r\n",
        "                        gt_batch = labels.data.float()\r\n",
        "                        gt = torch.cat((gt, labels.data.float()))\r\n",
        "\r\n",
        "                        # backward + optimize only if in training phase\r\n",
        "                        if phase == \"train\":\r\n",
        "                            loss.backward()\r\n",
        "                            optimizer.step()\r\n",
        "                            # calculate loss and accuracy\r\n",
        "                            train_loss += loss.item() * inputs.size(0)\r\n",
        "                            train_total += labels.size(0)\r\n",
        "                            train_correct += int(torch.sum(predictions == labels))\r\n",
        "\r\n",
        "                        if phase == \"val\":\r\n",
        "                            val_loss += loss.item() * inputs.size(0)\r\n",
        "                            scores, predictions = torch.max(outputs.data, 1)\r\n",
        "                            val_total += labels.size(0)\r\n",
        "                            val_correct += int(torch.sum(predictions == labels))\r\n",
        "\r\n",
        "                # save the model to a checkpoint \r\n",
        "                if phase == \"val\":\r\n",
        "                    checkpoint = {\r\n",
        "                    'epoch': epoch,\r\n",
        "                    'state_dict': model.state_dict(),\r\n",
        "                    'optimizer': optimizer.state_dict()\r\n",
        "                    }\r\n",
        "                    checkpoint_dir = '/content/drive/MyDrive/Object-CXR/Inception_v3/Checkpoint'\r\n",
        "                    best_model_dir = '/content/drive/MyDrive/Object-CXR/MODEL_DIR'\r\n",
        "                    fpr, tpr, _ = roc_curve(gt.tolist(), preds_prob.tolist())\r\n",
        "                    epoch_auc = round(auc(fpr, tpr), 3)\r\n",
        "                    is_best = True if (epoch_auc > best_auc) else False\r\n",
        "                    if epoch_auc > best_auc:\r\n",
        "                        best_auc = epoch_auc\r\n",
        "                        best_epoch = epoch\r\n",
        "                    save_checkpoint(checkpoint, is_best, checkpoint_dir, best_model_dir)\r\n",
        "\r\n",
        "            train_loss = round(train_loss/train_total, 3)\r\n",
        "            val_loss = round(val_loss/val_total, 3)\r\n",
        "            train_acc = round((float(train_correct) / train_total) * 100, 2)\r\n",
        "            val_acc = round((float(val_correct) / val_total) * 100, 2)\r\n",
        "\r\n",
        "            print(f\"Epoch: {epoch}, Train loss: {train_loss}, Train accuracy: {train_acc}\")\r\n",
        "            print(f\"\\t\\tVal loss: {val_loss}, Val accuracy: {val_acc}, AUC: {epoch_auc}\")\r\n",
        "\r\n",
        "            # Writing into our log file\r\n",
        "            f.write(f\"{model_name}, \"\r\n",
        "                    f\"{round(time.time(), 2)}, \"\r\n",
        "                    f\"TL: {train_loss}, \"\r\n",
        "                    f\"TA: {train_acc}, \"\r\n",
        "                    f\"VL: {val_loss}, \"\r\n",
        "                    f\"VA: {val_acc}, \"\r\n",
        "                    f\"AUC: {epoch_auc}\\n\")\r\n",
        "\r\n",
        "    print(f\"Training finished. Best AUC: {best_auc} on epoch {best_epoch}\")\r\n",
        "\r\n",
        "\r\n",
        "# --- Helper functions to print the performance of a model ---\r\n",
        "def print_acc_vs_epoch(file_path):\r\n",
        "    \"\"\"\r\n",
        "    This function produces an accuracy against epoch curve given a file path in which\r\n",
        "    performance data is stored.\r\n",
        "\r\n",
        "    :param file_path: The path in which performance data is stored.\r\n",
        "\r\n",
        "    :return: None\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    train_loss_arr = []\r\n",
        "    train_acc_arr = []\r\n",
        "    val_loss_arr = []\r\n",
        "    val_acc_arr = []\r\n",
        "\r\n",
        "    with open(file_path, 'r') as r_file:\r\n",
        "        for i, line in enumerate(r_file):\r\n",
        "            model_name, timestamp, train_loss, train_acc, val_loss, val_acc = line.split(', ')  # strings\r\n",
        "            # val_acc ends with a newline which we need to remove\r\n",
        "            val_acc = val_acc.rstrip(\"\\n\")\r\n",
        "            train_loss = float(train_loss.split(': ')[1])\r\n",
        "            train_acc = float(train_acc.split(': ')[1])\r\n",
        "            val_loss = float(val_loss.split(': ')[1])\r\n",
        "            val_acc = float(val_acc.split(': ')[1])\r\n",
        "\r\n",
        "            train_loss_arr.append(train_loss)\r\n",
        "            train_acc_arr.append(train_acc)\r\n",
        "            val_loss_arr.append(val_loss)\r\n",
        "            val_acc_arr.append(val_acc)\r\n",
        "\r\n",
        "        epoch_arr = np.arange(i+1)\r\n",
        "\r\n",
        "    plt.plot(epoch_arr, train_acc_arr, label=\"Train\")\r\n",
        "    plt.plot(epoch_arr, val_acc_arr, label=\"Val\")\r\n",
        "    plt.legend()\r\n",
        "    plt.xlabel(\"Epoch\")\r\n",
        "    plt.ylabel(\"Accuracy\")\r\n",
        "    plt.xlim(0, epoch_arr[-1] + 1)\r\n",
        "    plt.grid(True)\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av1vGfv_nEEV",
        "outputId": "60648f73-a4aa-4b26-b06c-f39b208e9c6a"
      },
      "source": [
        "# Creating our Inception_v3 model\r\n",
        "feature_extract = False  # when training set to False, when feature extracting set to True\r\n",
        "model_ft, input_size = initialise_inception_v3(num_classes=2, feature_extract=feature_extract,\r\n",
        "                                                                input_size=800, use_pretrained=True)\r\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inception3(\n",
            "  (Conv2d_1a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_2b_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Conv2d_3b_1x1): BasicConv2d(\n",
            "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (Conv2d_4a_3x3): BasicConv2d(\n",
            "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (Mixed_5b): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5c): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_5d): InceptionA(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch5x5_2): BasicConv2d(\n",
            "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6a): InceptionB(\n",
            "    (branch3x3): BasicConv2d(\n",
            "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6b): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6c): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6d): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_6e): InceptionC(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7dbl_5): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (AuxLogits): InceptionAux(\n",
            "    (conv0): BasicConv2d(\n",
            "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv1): BasicConv2d(\n",
            "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            "  (Mixed_7a): InceptionD(\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_2): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_3): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch7x7x3_4): BasicConv2d(\n",
            "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7b): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (Mixed_7c): InceptionE(\n",
            "    (branch1x1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3_2b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_1): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_2): BasicConv2d(\n",
            "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3a): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch3x3dbl_3b): BasicConv2d(\n",
            "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch_pool): BasicConv2d(\n",
            "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCWZ_97UnExz",
        "outputId": "fefb91dd-231c-47e6-b7fd-2aad8ad274c9"
      },
      "source": [
        "# Gather the parameters to be optimized\r\n",
        "params_to_update = model_ft.parameters()\r\n",
        "print(\"Params to learn: \")\r\n",
        "feature_extract = False\r\n",
        "if feature_extract:\r\n",
        "    params_to_update = []\r\n",
        "    for name, param in model_ft.named_parameters():\r\n",
        "        if param.requires_grad:\r\n",
        "            params_to_update.append(param)\r\n",
        "            print(\"\\t\", name)\r\n",
        "else:\r\n",
        "    for name, param in model_ft.named_parameters():\r\n",
        "        if param.requires_grad:\r\n",
        "            print(\"\\t\", name)\r\n",
        "total_params = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\r\n",
        "print(\"Number of params to learn:\", total_params)\r\n",
        "print(params_to_update)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn: \n",
            "\t Conv2d_1a_3x3.conv.weight\n",
            "\t Conv2d_1a_3x3.bn.weight\n",
            "\t Conv2d_1a_3x3.bn.bias\n",
            "\t Conv2d_2a_3x3.conv.weight\n",
            "\t Conv2d_2a_3x3.bn.weight\n",
            "\t Conv2d_2a_3x3.bn.bias\n",
            "\t Conv2d_2b_3x3.conv.weight\n",
            "\t Conv2d_2b_3x3.bn.weight\n",
            "\t Conv2d_2b_3x3.bn.bias\n",
            "\t Conv2d_3b_1x1.conv.weight\n",
            "\t Conv2d_3b_1x1.bn.weight\n",
            "\t Conv2d_3b_1x1.bn.bias\n",
            "\t Conv2d_4a_3x3.conv.weight\n",
            "\t Conv2d_4a_3x3.bn.weight\n",
            "\t Conv2d_4a_3x3.bn.bias\n",
            "\t Mixed_5b.branch1x1.conv.weight\n",
            "\t Mixed_5b.branch1x1.bn.weight\n",
            "\t Mixed_5b.branch1x1.bn.bias\n",
            "\t Mixed_5b.branch5x5_1.conv.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.weight\n",
            "\t Mixed_5b.branch5x5_1.bn.bias\n",
            "\t Mixed_5b.branch5x5_2.conv.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.weight\n",
            "\t Mixed_5b.branch5x5_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5b.branch_pool.conv.weight\n",
            "\t Mixed_5b.branch_pool.bn.weight\n",
            "\t Mixed_5b.branch_pool.bn.bias\n",
            "\t Mixed_5c.branch1x1.conv.weight\n",
            "\t Mixed_5c.branch1x1.bn.weight\n",
            "\t Mixed_5c.branch1x1.bn.bias\n",
            "\t Mixed_5c.branch5x5_1.conv.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.weight\n",
            "\t Mixed_5c.branch5x5_1.bn.bias\n",
            "\t Mixed_5c.branch5x5_2.conv.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.weight\n",
            "\t Mixed_5c.branch5x5_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5c.branch_pool.conv.weight\n",
            "\t Mixed_5c.branch_pool.bn.weight\n",
            "\t Mixed_5c.branch_pool.bn.bias\n",
            "\t Mixed_5d.branch1x1.conv.weight\n",
            "\t Mixed_5d.branch1x1.bn.weight\n",
            "\t Mixed_5d.branch1x1.bn.bias\n",
            "\t Mixed_5d.branch5x5_1.conv.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.weight\n",
            "\t Mixed_5d.branch5x5_1.bn.bias\n",
            "\t Mixed_5d.branch5x5_2.conv.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.weight\n",
            "\t Mixed_5d.branch5x5_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_5d.branch_pool.conv.weight\n",
            "\t Mixed_5d.branch_pool.bn.weight\n",
            "\t Mixed_5d.branch_pool.bn.bias\n",
            "\t Mixed_6a.branch3x3.conv.weight\n",
            "\t Mixed_6a.branch3x3.bn.weight\n",
            "\t Mixed_6a.branch3x3.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
            "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
            "\t Mixed_6b.branch1x1.conv.weight\n",
            "\t Mixed_6b.branch1x1.bn.weight\n",
            "\t Mixed_6b.branch1x1.bn.bias\n",
            "\t Mixed_6b.branch7x7_1.conv.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.weight\n",
            "\t Mixed_6b.branch7x7_1.bn.bias\n",
            "\t Mixed_6b.branch7x7_2.conv.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.weight\n",
            "\t Mixed_6b.branch7x7_2.bn.bias\n",
            "\t Mixed_6b.branch7x7_3.conv.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.weight\n",
            "\t Mixed_6b.branch7x7_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6b.branch_pool.conv.weight\n",
            "\t Mixed_6b.branch_pool.bn.weight\n",
            "\t Mixed_6b.branch_pool.bn.bias\n",
            "\t Mixed_6c.branch1x1.conv.weight\n",
            "\t Mixed_6c.branch1x1.bn.weight\n",
            "\t Mixed_6c.branch1x1.bn.bias\n",
            "\t Mixed_6c.branch7x7_1.conv.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.weight\n",
            "\t Mixed_6c.branch7x7_1.bn.bias\n",
            "\t Mixed_6c.branch7x7_2.conv.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.weight\n",
            "\t Mixed_6c.branch7x7_2.bn.bias\n",
            "\t Mixed_6c.branch7x7_3.conv.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.weight\n",
            "\t Mixed_6c.branch7x7_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6c.branch_pool.conv.weight\n",
            "\t Mixed_6c.branch_pool.bn.weight\n",
            "\t Mixed_6c.branch_pool.bn.bias\n",
            "\t Mixed_6d.branch1x1.conv.weight\n",
            "\t Mixed_6d.branch1x1.bn.weight\n",
            "\t Mixed_6d.branch1x1.bn.bias\n",
            "\t Mixed_6d.branch7x7_1.conv.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.weight\n",
            "\t Mixed_6d.branch7x7_1.bn.bias\n",
            "\t Mixed_6d.branch7x7_2.conv.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.weight\n",
            "\t Mixed_6d.branch7x7_2.bn.bias\n",
            "\t Mixed_6d.branch7x7_3.conv.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.weight\n",
            "\t Mixed_6d.branch7x7_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6d.branch_pool.conv.weight\n",
            "\t Mixed_6d.branch_pool.bn.weight\n",
            "\t Mixed_6d.branch_pool.bn.bias\n",
            "\t Mixed_6e.branch1x1.conv.weight\n",
            "\t Mixed_6e.branch1x1.bn.weight\n",
            "\t Mixed_6e.branch1x1.bn.bias\n",
            "\t Mixed_6e.branch7x7_1.conv.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.weight\n",
            "\t Mixed_6e.branch7x7_1.bn.bias\n",
            "\t Mixed_6e.branch7x7_2.conv.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.weight\n",
            "\t Mixed_6e.branch7x7_2.bn.bias\n",
            "\t Mixed_6e.branch7x7_3.conv.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.weight\n",
            "\t Mixed_6e.branch7x7_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
            "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
            "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
            "\t Mixed_6e.branch_pool.conv.weight\n",
            "\t Mixed_6e.branch_pool.bn.weight\n",
            "\t Mixed_6e.branch_pool.bn.bias\n",
            "\t AuxLogits.conv0.conv.weight\n",
            "\t AuxLogits.conv0.bn.weight\n",
            "\t AuxLogits.conv0.bn.bias\n",
            "\t AuxLogits.conv1.conv.weight\n",
            "\t AuxLogits.conv1.bn.weight\n",
            "\t AuxLogits.conv1.bn.bias\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t Mixed_7a.branch3x3_1.conv.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.weight\n",
            "\t Mixed_7a.branch3x3_1.bn.bias\n",
            "\t Mixed_7a.branch3x3_2.conv.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.weight\n",
            "\t Mixed_7a.branch3x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
            "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
            "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
            "\t Mixed_7b.branch1x1.conv.weight\n",
            "\t Mixed_7b.branch1x1.bn.weight\n",
            "\t Mixed_7b.branch1x1.bn.bias\n",
            "\t Mixed_7b.branch3x3_1.conv.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.weight\n",
            "\t Mixed_7b.branch3x3_1.bn.bias\n",
            "\t Mixed_7b.branch3x3_2a.conv.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.weight\n",
            "\t Mixed_7b.branch3x3_2a.bn.bias\n",
            "\t Mixed_7b.branch3x3_2b.conv.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.weight\n",
            "\t Mixed_7b.branch3x3_2b.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7b.branch_pool.conv.weight\n",
            "\t Mixed_7b.branch_pool.bn.weight\n",
            "\t Mixed_7b.branch_pool.bn.bias\n",
            "\t Mixed_7c.branch1x1.conv.weight\n",
            "\t Mixed_7c.branch1x1.bn.weight\n",
            "\t Mixed_7c.branch1x1.bn.bias\n",
            "\t Mixed_7c.branch3x3_1.conv.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.weight\n",
            "\t Mixed_7c.branch3x3_1.bn.bias\n",
            "\t Mixed_7c.branch3x3_2a.conv.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.weight\n",
            "\t Mixed_7c.branch3x3_2a.bn.bias\n",
            "\t Mixed_7c.branch3x3_2b.conv.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.weight\n",
            "\t Mixed_7c.branch3x3_2b.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
            "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
            "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
            "\t Mixed_7c.branch_pool.conv.weight\n",
            "\t Mixed_7c.branch_pool.bn.weight\n",
            "\t Mixed_7c.branch_pool.bn.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n",
            "Number of params to learn: 24348900\n",
            "<generator object Module.parameters at 0x7feb5bd23f68>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-UghgrjnL7d",
        "outputId": "8720c283-8793-432f-a2b1-3f32d00b8bbd"
      },
      "source": [
        "# Logging our losses and accuracy to a log file\r\n",
        "model_name = f\"inception_v3-{int(time.time())}\"\r\n",
        "log_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Log/incpetion_v3.txt'\r\n",
        "\r\n",
        "# Defining our optimizer and criterion\r\n",
        "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Start our training loop\r\n",
        "train_model(model_ft, dataLoaders_dict, criterion, optimizer, log_path, model_name, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "Epoch: 0, Train loss: 0.843, Train accuracy: 67.89\n",
            "\t\tVal loss: 0.486, Val accuracy: 83.0, AUC: 0.76\n",
            "Epoch 1/4\n",
            "----------\n",
            "Epoch: 1, Train loss: 0.754, Train accuracy: 76.83\n",
            "\t\tVal loss: 0.477, Val accuracy: 83.7, AUC: 0.821\n",
            "Epoch 2/4\n",
            "----------\n",
            "Epoch: 2, Train loss: 0.727, Train accuracy: 79.14\n",
            "\t\tVal loss: 0.479, Val accuracy: 82.7, AUC: 0.843\n",
            "Epoch 3/4\n",
            "----------\n",
            "Epoch: 3, Train loss: 0.718, Train accuracy: 79.84\n",
            "\t\tVal loss: 0.473, Val accuracy: 83.8, AUC: 0.853\n",
            "Epoch 4/4\n",
            "----------\n",
            "Epoch: 4, Train loss: 0.709, Train accuracy: 80.51\n",
            "\t\tVal loss: 0.467, Val accuracy: 84.3, AUC: 0.864\n",
            "Training finished. Best AUC: 0.864 on epoch 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmmUYMKUxSoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df77ae6e-44e5-4216-81d6-44a4ee387825"
      },
      "source": [
        "# Continue from where we left off and train for 10 more epochs\r\n",
        "# Intialising the inception v3 model and optimizer again\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "torch.backends.cudnn.benchmark = True\r\n",
        "feature_extract = False\r\n",
        "model, input_size = initialise_inception_v3(num_classes=2, feature_extract=feature_extract,\r\n",
        "                                           input_size=800, use_pretrained=True)\r\n",
        "model.to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# Load our saved states back to our model using load_checkpoint() function defined above\r\n",
        "checkpoint_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Checkpoint/checkpoint.pt'\r\n",
        "model, optimizer, start_epoch = load_checkpoint(checkpoint_path, model, optimizer)\r\n",
        "\r\n",
        "# Continue training, and logging the performance to the same text file\r\n",
        "model_name = f\"inception_v3-{int(time.time())}\"\r\n",
        "log_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Log/incpetion_v3.txt'\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "resume_training(model, dataLoaders_dict, criterion, optimizer, log_path,\r\n",
        "                model_name, start_epoch + 1, 0.864, 4, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/14\n",
            "----------\n",
            "Epoch: 5, Train loss: 0.705, Train accuracy: 81.01\n",
            "\t\tVal loss: 0.475, Val accuracy: 83.6, AUC: 0.867\n",
            "Epoch 6/14\n",
            "----------\n",
            "Epoch: 6, Train loss: 0.703, Train accuracy: 81.09\n",
            "\t\tVal loss: 0.469, Val accuracy: 84.0, AUC: 0.871\n",
            "Epoch 7/14\n",
            "----------\n",
            "Epoch: 7, Train loss: 0.688, Train accuracy: 82.47\n",
            "\t\tVal loss: 0.458, Val accuracy: 85.2, AUC: 0.884\n",
            "Epoch 8/14\n",
            "----------\n",
            "Epoch: 8, Train loss: 0.676, Train accuracy: 82.96\n",
            "\t\tVal loss: 0.467, Val accuracy: 83.4, AUC: 0.893\n",
            "Epoch 9/14\n",
            "----------\n",
            "Epoch: 9, Train loss: 0.667, Train accuracy: 83.81\n",
            "\t\tVal loss: 0.467, Val accuracy: 84.0, AUC: 0.899\n",
            "Epoch 10/14\n",
            "----------\n",
            "Epoch: 10, Train loss: 0.663, Train accuracy: 84.34\n",
            "\t\tVal loss: 0.458, Val accuracy: 84.8, AUC: 0.902\n",
            "Epoch 11/14\n",
            "----------\n",
            "Epoch: 11, Train loss: 0.659, Train accuracy: 84.58\n",
            "\t\tVal loss: 0.472, Val accuracy: 83.6, AUC: 0.902\n",
            "Epoch 12/14\n",
            "----------\n",
            "Epoch: 12, Train loss: 0.661, Train accuracy: 84.28\n",
            "\t\tVal loss: 0.464, Val accuracy: 84.4, AUC: 0.901\n",
            "Epoch 13/14\n",
            "----------\n",
            "Epoch: 13, Train loss: 0.649, Train accuracy: 84.97\n",
            "\t\tVal loss: 0.462, Val accuracy: 84.2, AUC: 0.908\n",
            "Epoch 14/14\n",
            "----------\n",
            "Epoch: 14, Train loss: 0.648, Train accuracy: 85.17\n",
            "\t\tVal loss: 0.452, Val accuracy: 85.5, AUC: 0.912\n",
            "Training finished. Best AUC: 0.912 on epoch 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwvbLKp0u9EO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788,
          "referenced_widgets": [
            "066407e67a334e2c9eb30fd70e90865d",
            "eceb053a76a94c69a22db305c176ecd7",
            "b748bea21b3a401dac9f7f5199eb7695",
            "ba3dc6ae1b964a90a8da3ed7bd59959e",
            "d2621f05bd4a4d6584c831489b2d0e6e",
            "79e590d0c3974f6aa994b546a78030e9",
            "3f98dbfc3d6241d69dbfb403cd5ce8bf",
            "03706c28db19418e8a23fb5cb2b016a9"
          ]
        },
        "outputId": "9353b4e5-cf60-43be-cf87-e84f80570568"
      },
      "source": [
        "# Continue from where we left off and train for 10 more epochs\r\n",
        "# Intialising the inception v3 model and optimizer again\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "torch.backends.cudnn.benchmark = True\r\n",
        "feature_extract = False\r\n",
        "model, input_size = initialise_inception_v3(num_classes=2, feature_extract=feature_extract,\r\n",
        "                                           input_size=800, use_pretrained=True)\r\n",
        "model.to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# Load our saved states back to our model using load_checkpoint() function defined above\r\n",
        "checkpoint_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Checkpoint/checkpoint.pt'\r\n",
        "model, optimizer, start_epoch = load_checkpoint(checkpoint_path, model, optimizer)\r\n",
        "\r\n",
        "# Continue training, and logging the performance to the same text file\r\n",
        "model_name = f\"inception_v3-{int(time.time())}\"\r\n",
        "log_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Log/incpetion_v3.txt'\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "resume_training(model, dataLoaders_dict, criterion, optimizer, log_path,\r\n",
        "                model_name, start_epoch + 1, 0.912, 14, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "066407e67a334e2c9eb30fd70e90865d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "Epoch: 15, Train loss: 0.636, Train accuracy: 86.01\n",
            "\t\tVal loss: 0.446, Val accuracy: 86.4, AUC: 0.919\n",
            "Epoch 16/24\n",
            "----------\n",
            "Epoch: 16, Train loss: 0.648, Train accuracy: 85.05\n",
            "\t\tVal loss: 0.443, Val accuracy: 86.5, AUC: 0.912\n",
            "Epoch 17/24\n",
            "----------\n",
            "Epoch: 17, Train loss: 0.656, Train accuracy: 84.5\n",
            "\t\tVal loss: 0.468, Val accuracy: 83.8, AUC: 0.907\n",
            "Epoch 18/24\n",
            "----------\n",
            "Epoch: 18, Train loss: 0.644, Train accuracy: 85.26\n",
            "\t\tVal loss: 0.464, Val accuracy: 84.5, AUC: 0.917\n",
            "Epoch 19/24\n",
            "----------\n",
            "Epoch: 19, Train loss: 0.639, Train accuracy: 85.6\n",
            "\t\tVal loss: 0.445, Val accuracy: 86.7, AUC: 0.918\n",
            "Epoch 20/24\n",
            "----------\n",
            "Epoch: 20, Train loss: 0.637, Train accuracy: 85.99\n",
            "\t\tVal loss: 0.449, Val accuracy: 85.6, AUC: 0.918\n",
            "Epoch 21/24\n",
            "----------\n",
            "Epoch: 21, Train loss: 0.633, Train accuracy: 86.35\n",
            "\t\tVal loss: 0.446, Val accuracy: 86.3, AUC: 0.922\n",
            "Epoch 22/24\n",
            "----------\n",
            "Epoch: 22, Train loss: 0.627, Train accuracy: 86.71\n",
            "\t\tVal loss: 0.457, Val accuracy: 85.1, AUC: 0.924\n",
            "Epoch 23/24\n",
            "----------\n",
            "Epoch: 23, Train loss: 0.626, Train accuracy: 86.8\n",
            "\t\tVal loss: 0.438, Val accuracy: 87.2, AUC: 0.924\n",
            "Epoch 24/24\n",
            "----------\n",
            "Epoch: 24, Train loss: 0.621, Train accuracy: 87.09\n",
            "\t\tVal loss: 0.442, Val accuracy: 86.7, AUC: 0.928\n",
            "Training finished. Best AUC: 0.928 on epoch 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788,
          "referenced_widgets": [
            "41710ff70921448f91a5a1ffe4024f79",
            "515fa05dfd0545af9109fadfd053cfc6",
            "f15093d2e6db42cc8c6e9c9f9913c40e",
            "6aee97fb09534acb8ae873af3f250bae",
            "10feb342f9954c89a169536ba247fa2d",
            "746305292c2d4ad58dddb5c7bdc07787",
            "640c5160d11e48cb8f5133a19bae0a70",
            "b4d2cdf14ff348aba32efb8bad734d30"
          ]
        },
        "id": "emRrFM6vCINw",
        "outputId": "9f537fe8-a9d9-4e73-ea34-8328cdc58ce0"
      },
      "source": [
        "# Continue from where we left off and train for 10 more epochs\r\n",
        "# Intialising the inception v3 model and optimizer again\r\n",
        "use_cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "torch.backends.cudnn.benchmark = True\r\n",
        "feature_extract = False\r\n",
        "model, input_size = initialise_inception_v3(num_classes=2, feature_extract=feature_extract,\r\n",
        "                                           input_size=800, use_pretrained=True)\r\n",
        "model.to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# Load our saved states back to our model using load_checkpoint() function defined above\r\n",
        "checkpoint_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Checkpoint/checkpoint.pt'\r\n",
        "model, optimizer, start_epoch = load_checkpoint(checkpoint_path, model, optimizer)\r\n",
        "\r\n",
        "# Continue training, and logging the performance to the same text file\r\n",
        "model_name = f\"inception_v3-{int(time.time())}\"\r\n",
        "log_path = '/content/drive/MyDrive/Object-CXR/Inception_v3/Log/incpetion_v3.txt'\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "resume_training(model, dataLoaders_dict, criterion, optimizer, log_path,\r\n",
        "                model_name, start_epoch + 1, 0.928, 24, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41710ff70921448f91a5a1ffe4024f79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 25/34\n",
            "----------\n",
            "Epoch: 25, Train loss: 0.618, Train accuracy: 87.31\n",
            "\t\tVal loss: 0.441, Val accuracy: 86.8, AUC: 0.93\n",
            "Epoch 26/34\n",
            "----------\n",
            "Epoch: 26, Train loss: 0.621, Train accuracy: 87.14\n",
            "\t\tVal loss: 0.433, Val accuracy: 87.4, AUC: 0.928\n",
            "Epoch 27/34\n",
            "----------\n",
            "Epoch: 27, Train loss: 0.622, Train accuracy: 87.0\n",
            "\t\tVal loss: 0.439, Val accuracy: 87.3, AUC: 0.93\n",
            "Epoch 28/34\n",
            "----------\n",
            "Epoch: 28, Train loss: 0.61, Train accuracy: 87.74\n",
            "\t\tVal loss: 0.438, Val accuracy: 87.3, AUC: 0.933\n",
            "Epoch 29/34\n",
            "----------\n",
            "Epoch: 29, Train loss: 0.608, Train accuracy: 88.06\n",
            "\t\tVal loss: 0.439, Val accuracy: 86.7, AUC: 0.932\n",
            "Epoch 30/34\n",
            "----------\n",
            "Epoch: 30, Train loss: 0.614, Train accuracy: 87.6\n",
            "\t\tVal loss: 0.444, Val accuracy: 86.2, AUC: 0.931\n",
            "Epoch 31/34\n",
            "----------\n",
            "Epoch: 31, Train loss: 0.615, Train accuracy: 87.4\n",
            "\t\tVal loss: 0.439, Val accuracy: 87.0, AUC: 0.93\n",
            "Epoch 32/34\n",
            "----------\n",
            "Epoch: 32, Train loss: 0.61, Train accuracy: 87.78\n",
            "\t\tVal loss: 0.434, Val accuracy: 87.3, AUC: 0.932\n",
            "Epoch 33/34\n",
            "----------\n",
            "Epoch: 33, Train loss: 0.606, Train accuracy: 88.12\n",
            "\t\tVal loss: 0.439, Val accuracy: 86.7, AUC: 0.935\n",
            "Epoch 34/34\n",
            "----------\n",
            "Epoch: 34, Train loss: 0.613, Train accuracy: 87.72\n",
            "\t\tVal loss: 0.45, Val accuracy: 85.6, AUC: 0.931\n",
            "Training finished. Best AUC: 0.935 on epoch 33\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}